{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "data = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "data['target'] = pd.Series(boston.target)\n",
    "ipd(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "\n",
    "# Do a train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=10, random_state=42)\n",
    "\n",
    "# Create and fit regression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x_train, y_train)\n",
    "\n",
    "# Do prediction and calculate mean absolute error\n",
    "test_pred = linreg.predict(x_test)\n",
    "mean_absolute_error(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate ModelDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/mitdbg/modeldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./modeldb/client/python/setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pkg_resources\n",
    "#pkg_resources.require(\"modeldb==0.0.1a31\")\n",
    "#import modeldb.sklearn_native.ModelDbSyncer as mdb\n",
    "import modeldb.sklearn_native.ModelDbSyncer as mdb\n",
    "\n",
    "project = mdb.NewOrExistingProject(name=\"ModelDB Evaluation\", author=\"Nico\", description=\"using Bosten Housing Dataset\")\n",
    "experiment = mdb.NewOrExistingExperiment(name=\"Simple model training\", description=\"\")\n",
    "syncer = mdb.Syncer(\n",
    "    project,\n",
    "    experiment,\n",
    "    mdb.NewExperimentRun(\"Linear Regression\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modeldb.sklearn_native.ModelDbSyncer as mdb\n",
    "from modeldb.sklearn_native import SyncableMetrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Do a train_test_split\n",
    "x_train, x_test, y_train, y_test = mdb.cross_validation.train_test_split_sync(data.iloc[:,:-1], data.iloc[:,-1], test_size=10, random_state=42)\n",
    "\n",
    "# Create and fit regression\n",
    "linreg = mdb.linear_model.LinearRegression()\n",
    "linreg.fit_sync(x_train, y_train)\n",
    "\n",
    "# Do prediction and calculate mean absolute error\n",
    "test_pred = linreg.predict_sync(x_test)\n",
    "mae = SyncableMetrics.compute_metrics(linreg, mean_absolute_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "\n",
    "# Sync with the backend service\n",
    "syncer.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test some other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syncer = mdb.Syncer(project,experiment,mdb.NewExperimentRun(\"Ridge\"))\n",
    "\n",
    "model = mdb.linear_model.Ridge()\n",
    "model.fit_sync(x_train, y_train)\n",
    "test_pred = model.predict_sync(x_test)\n",
    "\n",
    "SyncableMetrics.compute_metrics(model, mean_absolute_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "mse = SyncableMetrics.compute_metrics(model, mean_squared_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "syncer.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syncer = mdb.Syncer(project,experiment,mdb.NewExperimentRun(\"Lasso\"))\n",
    "\n",
    "model = mdb.linear_model.Lasso()\n",
    "model.fit_sync(x_train,y_train)\n",
    "test_pred = model.predict_sync(x_test)\n",
    "\n",
    "mae = SyncableMetrics.compute_metrics(model, mean_absolute_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "mse = SyncableMetrics.compute_metrics(model, mean_squared_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "syncer.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syncer.set_experiment_run(mdb.NewExperimentRun(\"ElasticNet\"))\n",
    "\n",
    "model = mdb.linear_model.ElasticNet()\n",
    "model.fit_sync(x_train, y_train)\n",
    "test_pred = model.predict_sync(x_test)\n",
    "\n",
    "mae = SyncableMetrics.compute_metrics(model, mean_absolute_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "mse = SyncableMetrics.compute_metrics(model, mean_squared_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "syncer.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=10, random_state=42)\n",
    "\n",
    "tuned_parameters = {\n",
    "    'n_jobs': (1,2,3)\n",
    "}\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "print(sorted(clf.cv_results_.keys()))\n",
    "from sklearn.metrics import mean_squared_error # Same as the computation above the plot\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ModelDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mdb.NewOrExistingExperiment(name=\"Grid Search\", description=\"\")\n",
    "syncer = mdb.Syncer(project,experiment,mdb.NewExperimentRun(\"ElasticNet\"))\n",
    "\n",
    "model = mdb.linear_model.ElasticNet()\n",
    "parameters = {\n",
    "    'alpha': (10,5,1,0.5,0.1),\n",
    "    'l1_ratio': (1,0.75,0.5,.25,0)\n",
    "    \n",
    "}\n",
    "scorer = sklearn.metrics.make_scorer(mean_absolute_error)\n",
    "\n",
    "clf = mdb.GridSearchCV(model, parameters, cv=5, scoring=scorer,error_score=100)\n",
    "\n",
    "# Fit the gridsearch\n",
    "clf.fit_sync(x_train, y_train)\n",
    "\n",
    "#test_pred = clf.predict(x_test)\n",
    "# Compute various metrics on the testing set\n",
    "#mae = SyncableMetrics.compute_metrics(clf, mean_absolute_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "#mse = SyncableMetrics.compute_metrics(clf, mean_squared_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "syncer.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syncer = mdb.Syncer(project,experiment,mdb.NewExperimentRun(\"Lasso\"))\n",
    "\n",
    "model = clf.best_estimator_\n",
    "model.fit_sync(x_train,y_train)\n",
    "test_pred = model.predict_sync(x_test)\n",
    "\n",
    "mae = SyncableMetrics.compute_metrics(model, mean_absolute_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "mse = SyncableMetrics.compute_metrics(model, mean_squared_error, y_test, test_pred, data.iloc[:,:-1].values,\"predictionCol\", 'target')\n",
    "syncer.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import decomposition\n",
    "\n",
    "# Creating the pipeline\n",
    "pca = decomposition.PCA()\n",
    "lr = mdb.linear_model.LinearRegression()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', lr)])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipe.fit_sync(x_train, y_train)\n",
    "\n",
    "test_pred = pipe.predict(x_test)\n",
    "# Compute various metrics on the testing set\n",
    "SyncableMetrics.compute_metrics(pipe, mean_absolute_error, y_test, test_pred, data.iloc[:,:-1].values, \"predictionCol\",'target')\n",
    "SyncableMetrics.compute_metrics(pipe, mean_squared_error, y_test, test_pred, data.iloc[:,:-1].values, \"predictionCol\",'target')\n",
    "\n",
    "syncer.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from modeldb.sklearn_native.ModelDbSyncer import *\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "x = digits.data[:1000]\n",
    "y = digits.target[:1000]\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet')\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    pipeline, parameters, cv=None, scoring='%s_weighted' % 'precision')\n",
    "\n",
    "clf.fit_sync(x, y)\n",
    "syncer.sync()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
